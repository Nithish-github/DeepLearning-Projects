{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3682957,"sourceType":"datasetVersion","datasetId":2136537}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/nithunith/vgg-net-classification?scriptVersionId=185879605\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":false,"execution":{"iopub.status.busy":"2024-06-28T03:55:38.944496Z","iopub.execute_input":"2024-06-28T03:55:38.945433Z","iopub.status.idle":"2024-06-28T03:55:46.070099Z","shell.execute_reply.started":"2024-06-28T03:55:38.94539Z","shell.execute_reply":"2024-06-28T03:55:46.068761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# General Imports","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.backends.cudnn as cudnn\nimport numpy as np\nimport torchvision\nfrom torch.optim import lr_scheduler\nfrom torchvision import models,transforms,datasets\nfrom torch.utils.data import DataLoader, random_split\nimport matplotlib.pyplot as plt\nimport time\nimport os\nfrom PIL import Image\nfrom tempfile import TemporaryDirectory\n\ncudnn.benchmark = True\nplt.ion()\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-06-28T03:55:46.072203Z","iopub.execute_input":"2024-06-28T03:55:46.07318Z","iopub.status.idle":"2024-06-28T03:55:52.309334Z","shell.execute_reply.started":"2024-06-28T03:55:46.073142Z","shell.execute_reply":"2024-06-28T03:55:52.308385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data agumentation and normalization for training","metadata":{}},{"cell_type":"code","source":"# Define transformations\ntrain_transform = transforms.Compose([\n    transforms.RandomResizedCrop(224),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\n#having only normalization for transformation\nval_transform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\n#load the dataset \ndataset = datasets.ImageFolder(root='/kaggle/input/tom-and-jerry-image-classification/tom_and_jerry/tom_and_jerry/')\n\n# Define the train-validation split ratio\ntrain_ratio = 0.7\nval_ratio = 0.3\ntotal_size = len(dataset)\ntrain_size = int(total_size * train_ratio)\nval_size = total_size - train_size\n\n# Split the dataset\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\n# Apply transformations to the datasets\ntrain_dataset.dataset.transform = train_transform\nval_dataset.dataset.transform = val_transform\n\n# Create DataLoader\ndataloaders = {\n    \n    'train' : DataLoader(dataset=train_dataset, batch_size=32, shuffle=True),\n    'val'   : DataLoader(dataset=val_dataset, batch_size=32, shuffle=False)\n    \n}\n\n# Calculate dataset sizes\ndataset_sizes = {'train': len(train_dataset), 'val': len(val_dataset)}","metadata":{"execution":{"iopub.status.busy":"2024-06-28T03:55:52.310667Z","iopub.execute_input":"2024-06-28T03:55:52.311127Z","iopub.status.idle":"2024-06-28T03:55:53.244371Z","shell.execute_reply.started":"2024-06-28T03:55:52.311098Z","shell.execute_reply":"2024-06-28T03:55:53.243248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#to have an idea about the encoding details\nprint(dataset.class_to_idx)\nclass_names = list(dataset.class_to_idx.keys())\nprint(\"Class names\",class_names)","metadata":{"execution":{"iopub.status.busy":"2024-06-28T03:55:53.246713Z","iopub.execute_input":"2024-06-28T03:55:53.247066Z","iopub.status.idle":"2024-06-28T03:55:53.252655Z","shell.execute_reply.started":"2024-06-28T03:55:53.247038Z","shell.execute_reply":"2024-06-28T03:55:53.251599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Image Visualization","metadata":{}},{"cell_type":"code","source":"def imshow(inp, title=None):\n    \"\"\"Display image for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)  # pause a bit so that plots are updated\n\n\n# Get a batch of training data\ninputs, classes = next(iter(dataloaders['train']))\n#setting the figure size\nplt.figure(figsize=(15,15))\n# Make a grid from batch\nout = torchvision.utils.make_grid(inputs)\n#function call to show the image\nimshow(out, title=[class_names[x] for x in classes])","metadata":{"execution":{"iopub.status.busy":"2024-06-28T03:55:53.254021Z","iopub.execute_input":"2024-06-28T03:55:53.254356Z","iopub.status.idle":"2024-06-28T03:55:55.458217Z","shell.execute_reply.started":"2024-06-28T03:55:53.254328Z","shell.execute_reply":"2024-06-28T03:55:55.457301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Training Script","metadata":{}},{"cell_type":"code","source":"def train_model(model, criterion, optimizer, scheduler, dataloaders, dataset_sizes, device, num_epochs=25):\n    since = time.time()\n\n    # Create a temporary directory to save training checkpoints\n    with TemporaryDirectory() as tempdir:\n        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n\n        torch.save(model.state_dict(), best_model_params_path)\n        best_acc = 0.0\n\n        for epoch in range(num_epochs):\n            print(f'Epoch {epoch}/{num_epochs - 1}')\n            print('-' * 10)\n\n            # Each epoch has a training and validation phase\n            for phase in ['train', 'val']:\n                if phase == 'train':\n                    model.train()  # Set model to training mode\n                else:\n                    model.eval()   # Set model to evaluate mode\n\n                running_loss = 0.0\n                running_corrects = 0\n\n                # Iterate over data.\n                for inputs, labels in dataloaders[phase]:\n                    inputs = inputs.to(device)\n                    labels = labels.to(device)\n\n                    # Zero the parameter gradients\n                    optimizer.zero_grad()\n\n                    # Forward\n                    # Track history if only in train\n                    with torch.set_grad_enabled(phase == 'train'):\n                        outputs = model(inputs)\n                        _, preds = torch.max(outputs, 1)\n                        loss = criterion(outputs, labels)\n\n                        # Backward + optimize only if in training phase\n                        if phase == 'train':\n                            loss.backward()\n                            optimizer.step()\n\n                    # Statistics\n                    \n                    running_loss += loss.item() * inputs.size(0)\n                    running_corrects += torch.sum(preds == labels.data)\n                    \n                if phase == 'train':\n                    scheduler.step()\n\n                epoch_loss = running_loss / dataset_sizes[phase]\n                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n\n                # Deep copy the model\n                if phase == 'val' and epoch_acc > best_acc:\n                    best_acc = epoch_acc\n                    torch.save(model.state_dict(), best_model_params_path)\n\n            print()\n\n        time_elapsed = time.time() - since\n        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n        print(f'Best val Acc: {best_acc:4f}')\n\n        # Load best model weights\n        model.load_state_dict(torch.load(best_model_params_path))\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2024-06-28T03:55:55.459872Z","iopub.execute_input":"2024-06-28T03:55:55.460206Z","iopub.status.idle":"2024-06-28T03:55:55.475084Z","shell.execute_reply.started":"2024-06-28T03:55:55.460179Z","shell.execute_reply":"2024-06-28T03:55:55.473885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Vizualizing the model predictions","metadata":{}},{"cell_type":"code","source":"def visualize_model(model, num_images=10):\n    was_training = model.training\n    model.eval()\n    images_so_far = 0\n    fig = plt.figure()\n\n    with torch.no_grad():\n        for i, (inputs, labels) in enumerate(dataloaders['val']):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n\n            for j in range(inputs.size()[0]):\n                images_so_far += 1\n                ax = plt.subplot(num_images//2, 2, images_so_far)\n                ax.axis('off')\n                ax.set_title(f'predicted: {class_names[preds[j]]}')\n                imshow(inputs.cpu().data[j])\n\n                if images_so_far == num_images:\n                    model.train(mode=was_training)\n                    return\n        model.train(mode=was_training) # restore the model to traning state if the model was in training","metadata":{"execution":{"iopub.status.busy":"2024-06-28T03:55:55.476841Z","iopub.execute_input":"2024-06-28T03:55:55.477215Z","iopub.status.idle":"2024-06-28T03:55:55.489482Z","shell.execute_reply.started":"2024-06-28T03:55:55.477181Z","shell.execute_reply":"2024-06-28T03:55:55.488299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Finetuning the VGG Model - Using the pre-trained for initialization and training the model","metadata":{}},{"cell_type":"code","source":"#Pytorch command to list all the avaliable models\nmodels.list_models()  ","metadata":{"execution":{"iopub.status.busy":"2024-06-28T03:55:55.49094Z","iopub.execute_input":"2024-06-28T03:55:55.491293Z","iopub.status.idle":"2024-06-28T03:55:55.506217Z","shell.execute_reply.started":"2024-06-28T03:55:55.491266Z","shell.execute_reply":"2024-06-28T03:55:55.505275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_ft = models.vgg11_bn(weights='IMAGENET1K_V1')\n","metadata":{"execution":{"iopub.status.busy":"2024-06-28T03:55:55.508357Z","iopub.execute_input":"2024-06-28T03:55:55.5087Z","iopub.status.idle":"2024-06-28T03:56:00.685899Z","shell.execute_reply.started":"2024-06-28T03:55:55.508663Z","shell.execute_reply":"2024-06-28T03:56:00.685032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print the model classifier\nprint(model_ft.classifier)\n\n# Modify the classifier part\n# The classifier is a sequential container; the last layer is the one we need to change\nnum_ftrs = model_ft.classifier[6].in_features\nmodel_ft.classifier[6] = nn.Linear(num_ftrs, len(class_names))\n\nprint(model_ft.classifier)","metadata":{"execution":{"iopub.status.busy":"2024-06-28T03:56:00.688917Z","iopub.execute_input":"2024-06-28T03:56:00.689247Z","iopub.status.idle":"2024-06-28T03:56:00.699687Z","shell.execute_reply.started":"2024-06-28T03:56:00.689217Z","shell.execute_reply":"2024-06-28T03:56:00.698689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#load the model to device\nmodel_ft = model_ft.to(device)\n\n# Modify the classifier part\n# The classifier is a sequential container; the last layer is the one we need to change\ncriterion = nn.CrossEntropyLoss()\n\n# Observe that all parameters are being optimized\noptimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n\n# Decay LR by a factor of 0.1 every 7 epochs\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)","metadata":{"execution":{"iopub.status.busy":"2024-06-28T03:56:00.700942Z","iopub.execute_input":"2024-06-28T03:56:00.701236Z","iopub.status.idle":"2024-06-28T03:56:01.028229Z","shell.execute_reply.started":"2024-06-28T03:56:00.701211Z","shell.execute_reply":"2024-06-28T03:56:01.027216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train the Model","metadata":{}},{"cell_type":"code","source":"model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,dataloaders,dataset_sizes,device,num_epochs=20)","metadata":{"execution":{"iopub.status.busy":"2024-06-28T03:56:01.029395Z","iopub.execute_input":"2024-06-28T03:56:01.02973Z","iopub.status.idle":"2024-06-28T04:27:28.671059Z","shell.execute_reply.started":"2024-06-28T03:56:01.029702Z","shell.execute_reply":"2024-06-28T04:27:28.670103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize the prediction","metadata":{}},{"cell_type":"code","source":"visualize_model(model_ft)","metadata":{"execution":{"iopub.status.busy":"2024-06-28T04:27:28.672445Z","iopub.execute_input":"2024-06-28T04:27:28.672824Z","iopub.status.idle":"2024-06-28T04:27:30.643027Z","shell.execute_reply.started":"2024-06-28T04:27:28.672771Z","shell.execute_reply":"2024-06-28T04:27:30.641342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model_ft.state_dict(), 'tom_jerry.pt')","metadata":{"execution":{"iopub.status.busy":"2024-06-28T04:27:30.6446Z","iopub.execute_input":"2024-06-28T04:27:30.644888Z","iopub.status.idle":"2024-06-28T04:27:31.671641Z","shell.execute_reply.started":"2024-06-28T04:27:30.644863Z","shell.execute_reply":"2024-06-28T04:27:31.670759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# Grad Cam","metadata":{}},{"cell_type":"code","source":"!pip install git+https://github.com/jacobgil/pytorch-grad-cam.git","metadata":{"execution":{"iopub.status.busy":"2024-06-28T04:44:15.002206Z","iopub.execute_input":"2024-06-28T04:44:15.002704Z","iopub.status.idle":"2024-06-28T04:44:48.661629Z","shell.execute_reply.started":"2024-06-28T04:44:15.002666Z","shell.execute_reply":"2024-06-28T04:44:48.66045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pytorch_grad_cam import GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\nfrom pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\nfrom pytorch_grad_cam.utils.image import show_cam_on_image\n\ntarget_layers = [model_ft.features[-1]]\n\ncam = GradCAM(model=model_ft, target_layers=target_layers)\n\ninputs, classes = next(iter(dataloaders['val']))\ninputs = inputs.to('cuda' if torch.cuda.is_available() else 'cpu')\nclasses = classes.to('cuda' if torch.cuda.is_available() else 'cpu')\n\n\n# Generate CAM for the batch\ntargets = [ClassifierOutputTarget(cls.item()) for cls in classes]\ngrayscale_cam = cam(input_tensor=inputs, targets=targets)\n\n# Convert to numpy and display\ninputs = inputs.cpu().numpy().transpose(0, 2, 3, 1)  # Convert to HWC format\ninputs = inputs * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])  # Denormalize\ninputs = np.clip(inputs, 0, 1)\n\n# Display the images and their corresponding CAMs\nfig, axes = plt.subplots(len(inputs), 2, figsize=(10, len(inputs) * 5))\nfor i in range(len(inputs)):\n    cam_image = show_cam_on_image(inputs[i], grayscale_cam[i], use_rgb=True)\n    \n    axes[i, 0].imshow(inputs[i])\n    axes[i, 0].set_title(f'Original Image - Class: {classes[i].item()}')\n    axes[i, 0].axis('off')\n    \n    axes[i, 1].imshow(cam_image)\n    axes[i, 1].set_title(f'Grad-CAM - Class: {classes[i].item()}')\n    axes[i, 1].axis('off')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-28T04:59:52.117249Z","iopub.execute_input":"2024-06-28T04:59:52.118173Z","iopub.status.idle":"2024-06-28T05:00:07.869701Z","shell.execute_reply.started":"2024-06-28T04:59:52.118136Z","shell.execute_reply":"2024-06-28T05:00:07.867895Z"},"trusted":true},"execution_count":null,"outputs":[]}]}