{"cells":[{"cell_type":"markdown","metadata":{},"source":["<a href=\"https://www.kaggle.com/code/nithunith/vgg-net-classification?scriptVersionId=185879605\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":false,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-06-28T03:55:38.945433Z","iopub.status.busy":"2024-06-28T03:55:38.944496Z","iopub.status.idle":"2024-06-28T03:55:46.070099Z","shell.execute_reply":"2024-06-28T03:55:46.068761Z","shell.execute_reply.started":"2024-06-28T03:55:38.94539Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"markdown","metadata":{},"source":["# General Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T03:55:46.07318Z","iopub.status.busy":"2024-06-28T03:55:46.072203Z","iopub.status.idle":"2024-06-28T03:55:52.309334Z","shell.execute_reply":"2024-06-28T03:55:52.308385Z","shell.execute_reply.started":"2024-06-28T03:55:46.073142Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.backends.cudnn as cudnn\n","import numpy as np\n","import torchvision\n","from torch.optim import lr_scheduler\n","from torchvision import models,transforms,datasets\n","from torch.utils.data import DataLoader, random_split\n","import matplotlib.pyplot as plt\n","import time\n","import os\n","from PIL import Image\n","from tempfile import TemporaryDirectory\n","\n","cudnn.benchmark = True\n","plt.ion()\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","metadata":{},"source":["# Data agumentation and normalization for training"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T03:55:52.311127Z","iopub.status.busy":"2024-06-28T03:55:52.310667Z","iopub.status.idle":"2024-06-28T03:55:53.244371Z","shell.execute_reply":"2024-06-28T03:55:53.243248Z","shell.execute_reply.started":"2024-06-28T03:55:52.311098Z"},"trusted":true},"outputs":[],"source":["# Define transformations\n","train_transform = transforms.Compose([\n","    transforms.RandomResizedCrop(224),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])\n","\n","#having only normalization for transformation\n","val_transform = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])\n","\n","#load the dataset \n","dataset = datasets.ImageFolder(root='/kaggle/input/tom-and-jerry-image-classification/tom_and_jerry/tom_and_jerry/')\n","\n","# Define the train-validation split ratio\n","train_ratio = 0.7\n","val_ratio = 0.3\n","total_size = len(dataset)\n","train_size = int(total_size * train_ratio)\n","val_size = total_size - train_size\n","\n","# Split the dataset\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","# Apply transformations to the datasets\n","train_dataset.dataset.transform = train_transform\n","val_dataset.dataset.transform = val_transform\n","\n","# Create DataLoader\n","dataloaders = {\n","    \n","    'train' : DataLoader(dataset=train_dataset, batch_size=32, shuffle=True),\n","    'val'   : DataLoader(dataset=val_dataset, batch_size=32, shuffle=False)\n","    \n","}\n","\n","# Calculate dataset sizes\n","dataset_sizes = {'train': len(train_dataset), 'val': len(val_dataset)}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T03:55:53.247066Z","iopub.status.busy":"2024-06-28T03:55:53.246713Z","iopub.status.idle":"2024-06-28T03:55:53.252655Z","shell.execute_reply":"2024-06-28T03:55:53.251599Z","shell.execute_reply.started":"2024-06-28T03:55:53.247038Z"},"trusted":true},"outputs":[],"source":["#to have an idea about the encoding details\n","print(dataset.class_to_idx)\n","class_names = list(dataset.class_to_idx.keys())\n","print(\"Class names\",class_names)"]},{"cell_type":"markdown","metadata":{},"source":["# Image Visualization"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T03:55:53.254356Z","iopub.status.busy":"2024-06-28T03:55:53.254021Z","iopub.status.idle":"2024-06-28T03:55:55.458217Z","shell.execute_reply":"2024-06-28T03:55:55.457301Z","shell.execute_reply.started":"2024-06-28T03:55:53.254328Z"},"trusted":true},"outputs":[],"source":["def imshow(inp, title=None):\n","    \"\"\"Display image for Tensor.\"\"\"\n","    inp = inp.numpy().transpose((1, 2, 0))\n","    mean = np.array([0.485, 0.456, 0.406])\n","    std = np.array([0.229, 0.224, 0.225])\n","    inp = std * inp + mean\n","    inp = np.clip(inp, 0, 1)\n","    plt.imshow(inp)\n","    if title is not None:\n","        plt.title(title)\n","    plt.pause(0.001)  # pause a bit so that plots are updated\n","\n","\n","# Get a batch of training data\n","inputs, classes = next(iter(dataloaders['train']))\n","#setting the figure size\n","plt.figure(figsize=(15,15))\n","# Make a grid from batch\n","out = torchvision.utils.make_grid(inputs)\n","#function call to show the image\n","imshow(out, title=[class_names[x] for x in classes])"]},{"cell_type":"markdown","metadata":{},"source":["# Model Training Script"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T03:55:55.460206Z","iopub.status.busy":"2024-06-28T03:55:55.459872Z","iopub.status.idle":"2024-06-28T03:55:55.475084Z","shell.execute_reply":"2024-06-28T03:55:55.473885Z","shell.execute_reply.started":"2024-06-28T03:55:55.460179Z"},"trusted":true},"outputs":[],"source":["def train_model(model, criterion, optimizer, scheduler, dataloaders, dataset_sizes, device, num_epochs=25):\n","    since = time.time()\n","\n","    # Create a temporary directory to save training checkpoints\n","    with TemporaryDirectory() as tempdir:\n","        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n","\n","        torch.save(model.state_dict(), best_model_params_path)\n","        best_acc = 0.0\n","\n","        for epoch in range(num_epochs):\n","            print(f'Epoch {epoch}/{num_epochs - 1}')\n","            print('-' * 10)\n","\n","            # Each epoch has a training and validation phase\n","            for phase in ['train', 'val']:\n","                if phase == 'train':\n","                    model.train()  # Set model to training mode\n","                else:\n","                    model.eval()   # Set model to evaluate mode\n","\n","                running_loss = 0.0\n","                running_corrects = 0\n","\n","                # Iterate over data.\n","                for inputs, labels in dataloaders[phase]:\n","                    inputs = inputs.to(device)\n","                    labels = labels.to(device)\n","\n","                    # Zero the parameter gradients\n","                    optimizer.zero_grad()\n","\n","                    # Forward\n","                    # Track history if only in train\n","                    with torch.set_grad_enabled(phase == 'train'):\n","                        outputs = model(inputs)\n","                        _, preds = torch.max(outputs, 1)\n","                        loss = criterion(outputs, labels)\n","\n","                        # Backward + optimize only if in training phase\n","                        if phase == 'train':\n","                            loss.backward()\n","                            optimizer.step()\n","\n","                    # Statistics\n","                    \n","                    running_loss += loss.item() * inputs.size(0)\n","                    running_corrects += torch.sum(preds == labels.data)\n","                    \n","                if phase == 'train':\n","                    scheduler.step()\n","\n","                epoch_loss = running_loss / dataset_sizes[phase]\n","                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n","\n","                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n","\n","                # Deep copy the model\n","                if phase == 'val' and epoch_acc > best_acc:\n","                    best_acc = epoch_acc\n","                    torch.save(model.state_dict(), best_model_params_path)\n","\n","            print()\n","\n","        time_elapsed = time.time() - since\n","        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n","        print(f'Best val Acc: {best_acc:4f}')\n","\n","        # Load best model weights\n","        model.load_state_dict(torch.load(best_model_params_path))\n","    return model\n"]},{"cell_type":"markdown","metadata":{},"source":["# Vizualizing the model predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T03:55:55.477215Z","iopub.status.busy":"2024-06-28T03:55:55.476841Z","iopub.status.idle":"2024-06-28T03:55:55.489482Z","shell.execute_reply":"2024-06-28T03:55:55.488299Z","shell.execute_reply.started":"2024-06-28T03:55:55.477181Z"},"trusted":true},"outputs":[],"source":["def visualize_model(model, num_images=10):\n","    was_training = model.training\n","    model.eval()\n","    images_so_far = 0\n","    fig = plt.figure()\n","\n","    with torch.no_grad():\n","        for i, (inputs, labels) in enumerate(dataloaders['val']):\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = model(inputs)\n","            _, preds = torch.max(outputs, 1)\n","\n","            for j in range(inputs.size()[0]):\n","                images_so_far += 1\n","                ax = plt.subplot(num_images//2, 2, images_so_far)\n","                ax.axis('off')\n","                ax.set_title(f'predicted: {class_names[preds[j]]}')\n","                imshow(inputs.cpu().data[j])\n","\n","                if images_so_far == num_images:\n","                    model.train(mode=was_training)\n","                    return\n","        model.train(mode=was_training) # restore the model to traning state if the model was in training"]},{"cell_type":"markdown","metadata":{},"source":["# 1. Finetuning the VGG Model - Using the pre-trained for initialization and training the model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T03:55:55.491293Z","iopub.status.busy":"2024-06-28T03:55:55.49094Z","iopub.status.idle":"2024-06-28T03:55:55.506217Z","shell.execute_reply":"2024-06-28T03:55:55.505275Z","shell.execute_reply.started":"2024-06-28T03:55:55.491266Z"},"trusted":true},"outputs":[],"source":["#Pytorch command to list all the avaliable models\n","models.list_models()  "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T03:55:55.5087Z","iopub.status.busy":"2024-06-28T03:55:55.508357Z","iopub.status.idle":"2024-06-28T03:56:00.685899Z","shell.execute_reply":"2024-06-28T03:56:00.685032Z","shell.execute_reply.started":"2024-06-28T03:55:55.508663Z"},"trusted":true},"outputs":[],"source":["model_ft = models.vgg11_bn(weights='IMAGENET1K_V1')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T03:56:00.689247Z","iopub.status.busy":"2024-06-28T03:56:00.688917Z","iopub.status.idle":"2024-06-28T03:56:00.699687Z","shell.execute_reply":"2024-06-28T03:56:00.698689Z","shell.execute_reply.started":"2024-06-28T03:56:00.689217Z"},"trusted":true},"outputs":[],"source":["#print the model classifier\n","print(model_ft.classifier)\n","\n","# Modify the classifier part\n","# The classifier is a sequential container; the last layer is the one we need to change\n","num_ftrs = model_ft.classifier[6].in_features\n","model_ft.classifier[6] = nn.Linear(num_ftrs, len(class_names))\n","\n","print(model_ft.classifier)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T03:56:00.701236Z","iopub.status.busy":"2024-06-28T03:56:00.700942Z","iopub.status.idle":"2024-06-28T03:56:01.028229Z","shell.execute_reply":"2024-06-28T03:56:01.027216Z","shell.execute_reply.started":"2024-06-28T03:56:00.701211Z"},"trusted":true},"outputs":[],"source":["#load the model to device\n","model_ft = model_ft.to(device)\n","\n","# Modify the classifier part\n","# The classifier is a sequential container; the last layer is the one we need to change\n","criterion = nn.CrossEntropyLoss()\n","\n","# Observe that all parameters are being optimized\n","optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n","\n","# Decay LR by a factor of 0.1 every 7 epochs\n","exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"]},{"cell_type":"markdown","metadata":{},"source":["# Train the Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T03:56:01.02973Z","iopub.status.busy":"2024-06-28T03:56:01.029395Z","iopub.status.idle":"2024-06-28T04:27:28.671059Z","shell.execute_reply":"2024-06-28T04:27:28.670103Z","shell.execute_reply.started":"2024-06-28T03:56:01.029702Z"},"trusted":true},"outputs":[],"source":["model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,dataloaders,dataset_sizes,device,num_epochs=20)"]},{"cell_type":"markdown","metadata":{},"source":["# Visualize the prediction"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T04:27:28.672824Z","iopub.status.busy":"2024-06-28T04:27:28.672445Z","iopub.status.idle":"2024-06-28T04:27:30.643027Z","shell.execute_reply":"2024-06-28T04:27:30.641342Z","shell.execute_reply.started":"2024-06-28T04:27:28.672771Z"},"trusted":true},"outputs":[],"source":["visualize_model(model_ft)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T04:27:30.644888Z","iopub.status.busy":"2024-06-28T04:27:30.6446Z","iopub.status.idle":"2024-06-28T04:27:31.671641Z","shell.execute_reply":"2024-06-28T04:27:31.670759Z","shell.execute_reply.started":"2024-06-28T04:27:30.644863Z"},"trusted":true},"outputs":[],"source":["torch.save(model_ft.state_dict(), 'tom_jerry.pt')"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":["# Grad Cam"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T04:44:15.002704Z","iopub.status.busy":"2024-06-28T04:44:15.002206Z","iopub.status.idle":"2024-06-28T04:44:48.661629Z","shell.execute_reply":"2024-06-28T04:44:48.66045Z","shell.execute_reply.started":"2024-06-28T04:44:15.002666Z"},"trusted":true},"outputs":[],"source":["!pip install git+https://github.com/jacobgil/pytorch-grad-cam.git"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T04:59:52.118173Z","iopub.status.busy":"2024-06-28T04:59:52.117249Z","iopub.status.idle":"2024-06-28T05:00:07.869701Z","shell.execute_reply":"2024-06-28T05:00:07.867895Z","shell.execute_reply.started":"2024-06-28T04:59:52.118136Z"},"trusted":true},"outputs":[],"source":["from pytorch_grad_cam import GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n","from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n","from pytorch_grad_cam.utils.image import show_cam_on_image\n","\n","target_layers = [model_ft.features[-1]]\n","\n","cam = GradCAM(model=model_ft, target_layers=target_layers)\n","\n","inputs, classes = next(iter(dataloaders['val']))\n","inputs = inputs.to('cuda' if torch.cuda.is_available() else 'cpu')\n","classes = classes.to('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","\n","# Generate CAM for the batch\n","targets = [ClassifierOutputTarget(cls.item()) for cls in classes]\n","grayscale_cam = cam(input_tensor=inputs, targets=targets)\n","\n","# Convert to numpy and display\n","inputs = inputs.cpu().numpy().transpose(0, 2, 3, 1)  # Convert to HWC format\n","inputs = inputs * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])  # Denormalize\n","inputs = np.clip(inputs, 0, 1)\n","\n","# Display the images and their corresponding CAMs\n","fig, axes = plt.subplots(len(inputs), 2, figsize=(10, len(inputs) * 5))\n","for i in range(len(inputs)):\n","    cam_image = show_cam_on_image(inputs[i], grayscale_cam[i], use_rgb=True)\n","    \n","    axes[i, 0].imshow(inputs[i])\n","    axes[i, 0].set_title(f'Original Image - Class: {classes[i].item()}')\n","    axes[i, 0].axis('off')\n","    \n","    axes[i, 1].imshow(cam_image)\n","    axes[i, 1].set_title(f'Grad-CAM - Class: {classes[i].item()}')\n","    axes[i, 1].axis('off')\n","\n","plt.tight_layout()\n","plt.show()"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":2136537,"sourceId":3682957,"sourceType":"datasetVersion"}],"dockerImageVersionId":30732,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
