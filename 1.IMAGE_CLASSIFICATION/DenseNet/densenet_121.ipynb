{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":4532039,"sourceType":"datasetVersion","datasetId":2579480}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-07-11T09:15:21.178343Z","iopub.execute_input":"2024-07-11T09:15:21.179276Z","iopub.status.idle":"2024-07-11T09:15:24.711435Z","shell.execute_reply.started":"2024-07-11T09:15:21.179244Z","shell.execute_reply":"2024-07-11T09:15:24.710467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# General Imports","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.backends.cudnn as cudnn\nimport numpy as np\nimport torchvision\nfrom torch.optim import lr_scheduler\nfrom torchvision import models,transforms,datasets\nfrom torch.utils.data import DataLoader, random_split\nimport matplotlib.pyplot as plt\nimport time\nimport os\nfrom PIL import Image\nfrom tempfile import TemporaryDirectory\n\ncudnn.benchmark = True\nplt.ion()\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-07-11T09:15:24.713237Z","iopub.execute_input":"2024-07-11T09:15:24.713666Z","iopub.status.idle":"2024-07-11T09:15:30.050683Z","shell.execute_reply.started":"2024-07-11T09:15:24.713638Z","shell.execute_reply":"2024-07-11T09:15:30.049677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Agumentation and Spliting","metadata":{}},{"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.RandomResizedCrop(224),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\n#having only normalization for transformation\nval_transform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\n#load the dataset \ntrain_dataset = datasets.ImageFolder(root='/kaggle/input/cards-image-datasetclassification/train/')\nval_dataset = datasets.ImageFolder(root='/kaggle/input/cards-image-datasetclassification/valid/')\n\n# Apply transformations to the datasets\ntrain_dataset.transform = train_transform\nval_dataset.transform = val_transform\n\n# Create DataLoader\ndataloaders = {\n    \n    'train' : DataLoader(dataset=train_dataset, batch_size=8, shuffle=True),\n    'val'   : DataLoader(dataset=val_dataset, batch_size=8, shuffle=False)\n    \n}\n\n# Calculate dataset sizes\ndataset_sizes = {'train': len(train_dataset), 'val': len(val_dataset)}\ndataset_sizes","metadata":{"execution":{"iopub.status.busy":"2024-07-11T09:15:30.051790Z","iopub.execute_input":"2024-07-11T09:15:30.052234Z","iopub.status.idle":"2024-07-11T09:15:30.150798Z","shell.execute_reply.started":"2024-07-11T09:15:30.052206Z","shell.execute_reply":"2024-07-11T09:15:30.149962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Class names","metadata":{}},{"cell_type":"code","source":"#to have an idea about the encoding details\nprint(train_dataset.class_to_idx,\"\\n\")\nclass_names = list(train_dataset.class_to_idx.keys())\nprint(\"Class names\",class_names)","metadata":{"execution":{"iopub.status.busy":"2024-07-11T09:15:30.151847Z","iopub.execute_input":"2024-07-11T09:15:30.152125Z","iopub.status.idle":"2024-07-11T09:15:30.157017Z","shell.execute_reply.started":"2024-07-11T09:15:30.152101Z","shell.execute_reply":"2024-07-11T09:15:30.156149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Image Visualization","metadata":{}},{"cell_type":"code","source":"def imshow(inp, title=None):\n    \"\"\"Display image for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)  # pause a bit so that plots are updated\n\n\n# Get a batch of training data\ninputs, classes = next(iter(dataloaders['train']))\n#setting the figure size\nplt.figure(figsize=(30,30))\n# Make a grid from batch\nout = torchvision.utils.make_grid(inputs)\n#function call to show the image\nimshow(out, title=[class_names[x] for x in classes])","metadata":{"execution":{"iopub.status.busy":"2024-07-11T09:15:30.160603Z","iopub.execute_input":"2024-07-11T09:15:30.161017Z","iopub.status.idle":"2024-07-11T09:15:31.338783Z","shell.execute_reply.started":"2024-07-11T09:15:30.160986Z","shell.execute_reply":"2024-07-11T09:15:31.337860Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Trainig Script","metadata":{}},{"cell_type":"code","source":"def train_model(model, criterion, optimizer, scheduler, dataloaders, dataset_sizes, device, num_epochs=25):\n    since = time.time()\n\n    # Create a temporary directory to save training checkpoints\n    with TemporaryDirectory() as tempdir:\n        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n\n        torch.save(model.state_dict(), best_model_params_path)\n        best_acc = 0.0\n\n        for epoch in range(num_epochs):\n            print(f'Epoch {epoch}/{num_epochs - 1}')\n            print('-' * 10)\n\n            # Each epoch has a training and validation phase\n            for phase in ['train', 'val']:\n                if phase == 'train':\n                    model.train()  # Set model to training mode\n                else:\n                    model.eval()   # Set model to evaluate mode\n\n                running_loss = 0.0\n                running_corrects = 0\n\n                # Iterate over data.\n                for inputs, labels in dataloaders[phase]:\n                    inputs = inputs.to(device)\n                    labels = labels.to(device)\n\n                    # Zero the parameter gradients\n                    optimizer.zero_grad()\n\n                    # Forward\n                    # Track history if only in train\n                    with torch.set_grad_enabled(phase == 'train'):\n                        outputs = model(inputs)\n                        _, preds = torch.max(outputs, 1)\n                        loss = criterion(outputs, labels)\n\n                        # Backward + optimize only if in training phase\n                        if phase == 'train':\n                            loss.backward()\n                            optimizer.step()\n\n                    # Statistics\n                    \n                    running_loss += loss.item() * inputs.size(0)\n                    running_corrects += torch.sum(preds == labels.data)\n                    \n                if phase == 'train':\n                    scheduler.step()\n\n                epoch_loss = running_loss / dataset_sizes[phase]\n                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n\n                # Deep copy the model\n                if phase == 'val' and epoch_acc > best_acc:\n                    best_acc = epoch_acc\n                    torch.save(model.state_dict(), best_model_params_path)\n\n            print()\n\n        time_elapsed = time.time() - since\n        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n        print(f'Best val Acc: {best_acc:4f}')\n\n        # Load best model weights\n        model.load_state_dict(torch.load(best_model_params_path))\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-07-11T09:15:31.340359Z","iopub.execute_input":"2024-07-11T09:15:31.340664Z","iopub.status.idle":"2024-07-11T09:15:31.353878Z","shell.execute_reply.started":"2024-07-11T09:15:31.340637Z","shell.execute_reply":"2024-07-11T09:15:31.352844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Vizualizing the Model Output","metadata":{}},{"cell_type":"code","source":"def visualize_model(model, num_images=10):\n    was_training = model.training\n    model.eval()\n    images_so_far = 0\n    fig = plt.figure()\n\n    with torch.no_grad():\n        for i, (inputs, labels) in enumerate(dataloaders['val']):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n\n            for j in range(inputs.size()[0]):\n                images_so_far += 1\n                ax = plt.subplot(num_images//2, 2, images_so_far)\n                ax.axis('off')\n                ax.set_title(f'predicted: {class_names[preds[j]]}')\n                imshow(inputs.cpu().data[j])\n\n                if images_so_far == num_images:\n                    model.train(mode=was_training)\n                    return\n        model.train(mode=was_training) # restore the model to traning state if the model was in training","metadata":{"execution":{"iopub.status.busy":"2024-07-11T09:15:31.355209Z","iopub.execute_input":"2024-07-11T09:15:31.355567Z","iopub.status.idle":"2024-07-11T09:15:31.367557Z","shell.execute_reply.started":"2024-07-11T09:15:31.355527Z","shell.execute_reply":"2024-07-11T09:15:31.366690Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# List the avaliable models","metadata":{}},{"cell_type":"code","source":"models.list_models()","metadata":{"execution":{"iopub.status.busy":"2024-07-11T09:15:31.368708Z","iopub.execute_input":"2024-07-11T09:15:31.369029Z","iopub.status.idle":"2024-07-11T09:15:31.381551Z","shell.execute_reply.started":"2024-07-11T09:15:31.369004Z","shell.execute_reply":"2024-07-11T09:15:31.380677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dense Model as Feature Extractor","metadata":{}},{"cell_type":"code","source":"model_ft = models.densenet121(weights='IMAGENET1K_V1')\n","metadata":{"execution":{"iopub.status.busy":"2024-07-11T09:15:31.382690Z","iopub.execute_input":"2024-07-11T09:15:31.382971Z","iopub.status.idle":"2024-07-11T09:15:31.948712Z","shell.execute_reply.started":"2024-07-11T09:15:31.382947Z","shell.execute_reply":"2024-07-11T09:15:31.947753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print the model classifier\nprint(model_ft.classifier)\n\n# Modify the classifier part\n# Get the number of input features to the classifier\nnum_ftrs = model_ft.classifier.in_features\n\n# # Modify the classifier to match the number of classes in your dataset\nmodel_ft.classifier = nn.Linear(num_ftrs, len(class_names))","metadata":{"execution":{"iopub.status.busy":"2024-07-11T09:15:31.949982Z","iopub.execute_input":"2024-07-11T09:15:31.950270Z","iopub.status.idle":"2024-07-11T09:15:31.956338Z","shell.execute_reply.started":"2024-07-11T09:15:31.950245Z","shell.execute_reply":"2024-07-11T09:15:31.955433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#load the model to device\nmodel_ft = model_ft.to(device)\n\n# Modify the classifier part\n# The classifier is a sequential container; the last layer is the one we need to change\ncriterion = nn.CrossEntropyLoss()\n\n# Observe that all parameters are being optimized\noptimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n\n# Decay LR by a factor of 0.1 every 7 epochs\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)","metadata":{"execution":{"iopub.status.busy":"2024-07-11T09:15:31.957480Z","iopub.execute_input":"2024-07-11T09:15:31.957850Z","iopub.status.idle":"2024-07-11T09:15:32.167737Z","shell.execute_reply.started":"2024-07-11T09:15:31.957825Z","shell.execute_reply":"2024-07-11T09:15:32.166877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train the Model","metadata":{}},{"cell_type":"code","source":"model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,dataloaders,dataset_sizes,device,num_epochs=20)","metadata":{"execution":{"iopub.status.busy":"2024-07-11T09:15:32.168861Z","iopub.execute_input":"2024-07-11T09:15:32.169162Z","iopub.status.idle":"2024-07-11T09:50:49.016107Z","shell.execute_reply.started":"2024-07-11T09:15:32.169138Z","shell.execute_reply":"2024-07-11T09:50:49.015145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Output","metadata":{}},{"cell_type":"code","source":"visualize_model(model_ft)","metadata":{"execution":{"iopub.status.busy":"2024-07-11T09:50:49.017382Z","iopub.execute_input":"2024-07-11T09:50:49.017720Z","iopub.status.idle":"2024-07-11T09:50:50.556679Z","shell.execute_reply.started":"2024-07-11T09:50:49.017694Z","shell.execute_reply":"2024-07-11T09:50:50.555336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Grad Cam","metadata":{}},{"cell_type":"code","source":"!pip install git+https://github.com/jacobgil/pytorch-grad-cam.git","metadata":{"execution":{"iopub.status.busy":"2024-07-11T09:56:09.176796Z","iopub.execute_input":"2024-07-11T09:56:09.177715Z","iopub.status.idle":"2024-07-11T09:56:39.376686Z","shell.execute_reply.started":"2024-07-11T09:56:09.177681Z","shell.execute_reply":"2024-07-11T09:56:39.375680Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pytorch_grad_cam import GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\nfrom pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\nfrom pytorch_grad_cam.utils.image import show_cam_on_image\n\ntarget_layers = [model_ft.features[-1]]\n\ncam = GradCAM(model=model_ft, target_layers=target_layers)\n\ninputs, classes = next(iter(dataloaders['val']))\ninputs = inputs.to('cuda' if torch.cuda.is_available() else 'cpu')\nclasses = classes.to('cuda' if torch.cuda.is_available() else 'cpu')\n\n\n# Generate CAM for the batch\ntargets = [ClassifierOutputTarget(cls.item()) for cls in classes]\ngrayscale_cam = cam(input_tensor=inputs, targets=targets)\n\n# Convert to numpy and display\ninputs = inputs.cpu().numpy().transpose(0, 2, 3, 1)  # Convert to HWC format\ninputs = inputs * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])  # Denormalize\ninputs = np.clip(inputs, 0, 1)\n\n# Display the images and their corresponding CAMs\nfig, axes = plt.subplots(len(inputs), 2, figsize=(10, len(inputs) * 5))\nfor i in range(len(inputs)):\n    cam_image = show_cam_on_image(inputs[i], grayscale_cam[i], use_rgb=True)\n    \n    axes[i, 0].imshow(inputs[i])\n    axes[i, 0].set_title(f'Original Image - Class: {classes[i].item()}')\n    axes[i, 0].axis('off')\n    \n    axes[i, 1].imshow(cam_image)\n    axes[i, 1].set_title(f'Grad-CAM - Class: {classes[i].item()}')\n    axes[i, 1].axis('off')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-11T09:56:44.483225Z","iopub.execute_input":"2024-07-11T09:56:44.483621Z","iopub.status.idle":"2024-07-11T09:56:49.343586Z","shell.execute_reply.started":"2024-07-11T09:56:44.483586Z","shell.execute_reply":"2024-07-11T09:56:49.342250Z"},"trusted":true},"execution_count":null,"outputs":[]}]}